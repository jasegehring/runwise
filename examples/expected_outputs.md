# Runwise Example Outputs

This document shows example outputs from Runwise commands to help you understand what to expect.

## Understanding Data Sources

Runwise works with multiple data sources. Choose the right commands based on your setup:

| Data Source | Commands | Description |
|-------------|----------|-------------|
| **W&B Local** | `list`, `run`, `history`, `stats`, `keys` | Reads from local `wandb/` directory |
| **Local JSONL** | `local` | Standalone log files in `logs/` |
| **W&B Cloud** | `api` | Remote access (requires `pip install wandb`) |
| **TensorBoard** | `tb` | tfevents files (requires `pip install tensorboard`) |

## List Runs

```bash
runwise list
```

**Output:**
```
RECENT RUNS (My ML Project):

ID           State     Date            Steps     Accuracy        Trend
------------------------------------------------------------------------
xyz789       RUNNING   2025-12-14      5,000       82.3%    ▇▆▅▄▃▂▁▁↓
abc123       FINISHED  2025-12-14     50,000       95.2%    ▇▅▃▂▁▁▁▁↓
def456       CRASHED   2025-12-13      2,341       45.0%    ▁▁▂▅▇▇▇▇↑
```

## Run Summary

```bash
runwise latest
```

**Output:**
```
=== My ML Project Run Summary ===
Run: abc123xyz | Step: 50,000 | Runtime: 12.5h
Name: lr-sweep-0.001
Tags: sweep, lr-test

ANOMALIES:
  ! Overfitting: val/train ratio +35% vs baseline

TRAINING:
  Loss: 0.2341  ▇▆▅▄▃▂▂▁▁▁
  Accuracy: 87.3%  ▁▂▃▄▅▆▇▇▇█

VALIDATION:
  Validation: 85.2%
  Test: 83.7%
```

## Run Comparison

```bash
runwise compare abc123 def456
```

**Output:**
```
COMPARISON: abc123 vs def456

  A: lr-sweep-0.001
  B: lr-sweep-0.0001

Metric                        Run A        Run B      Delta
-----------------------------------------------------------------
train/accuracy                 92.0%        88.0%      -4.0%
train/loss                    0.2341       0.3456     +0.1115
val/accuracy                   87.0%        85.0%      -2.0%
val/loss                      0.3654       0.4123     +0.0469

CONFIG DIFFERENCES:
Parameter                       Run A           Run B
------------------------------------------------------------
learning_rate                   0.001          0.0001
```

## History Statistics

```bash
runwise stats -k loss,val_loss
```

**Output:**
```
HISTORY STATS: abc123 (1,000 steps)

Metric                    Min        Max       Mean      Final     NaN
----------------------------------------------------------------------
loss                   0.2341     2.4523     0.8234     0.2341       0
val_loss               0.3654     2.5234     0.9876     0.3654       0
```

## Downsampled History (CSV)

```bash
runwise history -k loss,val_loss -n 5
```

**Output:**
```
step,loss,val_loss
0,2.4523,2.5234
250,1.0543,1.1234
500,0.5432,0.6321
750,0.3212,0.4345
1000,0.2341,0.3654
```

## Config/Hyperparameters

```bash
runwise config
```

**Output:**
```
CONFIG: abc123

  batch_size: 64
  dropout: 0.15
  learning_rate: 5.00e-04
  model: transformer
  num_layers: 8
```

## Best Run

```bash
runwise best val_loss
```

**Output:**
```
BEST RUN BY val_loss (from last 10 runs):

  BEST: abc123 = 0.1234

Rank   Run ID       State            val_loss
---------------------------------------------
1      abc123       finished           0.1234 *
2      def456       finished           0.1567
3      ghi789       crashed            0.8901
```

## Stability Analysis

```bash
runwise stability -k loss,val_loss
```

**Output:**
```
STABILITY ANALYSIS: abc123
Window size: 100 steps | Total: 50,000 steps

Metric           Slope/1k  Trend    Avg Std  Final Std     Status
--------------------------------------------------------------------
loss             -0.0023      ↓     0.0234     0.0012     STABLE
val_loss         -0.0015      →     0.0456     0.0089   MODERATE

Slope/1k: change per 1000 steps (robust Theil-Sen estimate)
Trend: ↓=stabilizing  →=steady  ↑=destabilizing (variance trend)
Status: STABLE (<5% rel. variance) | MODERATE (5-15%) | NOISY (>15%)
```

The **Slope/1k** column shows the rate of change per 1000 training steps, calculated using the Theil-Sen estimator (robust to outliers/noise). Negative values mean the metric is decreasing (good for loss).

### Stability as CSV

```bash
runwise stability -k loss --csv -n 5
```

**Output:**
```csv
step,loss_mean,loss_std
0,2.4523,0.0000
12500,0.8234,0.0456
25000,0.4567,0.0234
37500,0.3123,0.0156
50000,0.2341,0.0089
```

## Markdown Output

```bash
runwise latest --format md
```

**Output:**
```markdown
## Run Summary: `abc123xyz`

| Metric | Value |
|--------|-------|
| Run | `abc123xyz` |
| Step | `50,000` |
| Runtime | `12.5h` |

### ANOMALIES

> **Warning:** Overfitting: val/train ratio +35% vs baseline

### TRAINING

- **Loss:** `0.2341` ▇▆▅▄▃▂▂▁▁▁
- **Accuracy:** `87.3%` ▁▂▃▄▅▆▇▇▇█

### VALIDATION

- **Validation:** `85.2%`
- **Test:** `83.7%`

### Run Context
- **Name:** lr-sweep-0.001
- **Tags:** `sweep` `lr-test`

---
*Generated by [Runwise](https://github.com/jasegehring/runwise)*
```

## W&B API Usage

```bash
runwise api --project my-project --entity my-team
```

**Output:**
```
W&B RUNS (API):

ID           Name                 State      Steps    Runtime
----------------------------------------------------------------------
abc123xyz    lr-sweep-0.001       finished    50,000      12.5h
  └─ [sweep, lr-test]
def456xyz    lr-sweep-0.0001      finished    48,000      11.2h
  └─ [sweep, lr-test]
```

## TensorBoard Support

```bash
runwise tb
```

**Output:**
```
TENSORBOARD RUNS:

Run ID                              Steps      Runtime     Tags
-----------------------------------------------------------------
train_1                            100,000        24.5h        8
train_2                             50,000        12.1h        6
```

## Available Metric Keys

```bash
runwise keys
```

**Output:**
```
Available keys:
grad_norm
loss
lr
train/accuracy
train/loss
val/accuracy
val/loss
```

---

## Local JSONL Logs

For standalone JSONL files (not W&B runs), use `runwise local`.

### List Local Logs

```bash
runwise local
```

**Output:**
```
LOCAL LOGS (in logs/ directory):

  metrics_20251214_115218.jsonl: 1000 records, step 1000
    keys: loss, val_loss, accuracy, lr, grad_norm...
  training_log.jsonl: 500 records, step 500
    keys: train/loss, train/accuracy, val/loss...

Usage: runwise local <file> [--keys | --history -k <keys> | --stats -k <keys>]
```

### List Keys in Local Log

```bash
runwise local metrics.jsonl --keys
```

**Output:**
```
Available keys in metrics.jsonl:
accuracy
grad_norm
loss
lr
val_accuracy
val_loss
```

### Get History from Local Log

```bash
runwise local metrics.jsonl --history -k loss,val_loss -n 5
```

**Output:**
```
step,loss,val_loss
0,2.4523,2.5234
250,1.0543,1.1234
500,0.5432,0.6321
750,0.3212,0.4345
1000,0.2341,0.3654
```

### Get Statistics from Local Log

```bash
runwise local metrics.jsonl --stats -k loss,val_loss
```

**Output:**
```
LOCAL LOG STATS: metrics.jsonl (1,000 records)

Metric               Min        Max       Mean      Final    NaN
----------------------------------------------------------------------
loss                0.2341     2.4523     0.8234     0.2341      0
val_loss            0.3654     2.5234     0.9876     0.3654      0
```

### Get Stability from Local Log

```bash
runwise local metrics.jsonl --stability -k loss,val_loss
```

**Output:**
```
STABILITY ANALYSIS: metrics.jsonl
Window size: 100 steps | Total: 1,000 steps

Metric           Slope/1k  Trend    Avg Std  Final Std     Status
--------------------------------------------------------------------
loss             -0.0156      ↓     0.0456     0.0089     STABLE
val_loss         -0.0098      →     0.0678     0.0123   MODERATE

Slope/1k: change per 1000 steps (robust Theil-Sen estimate)
Trend: ↓=stabilizing  →=steady  ↑=destabilizing (variance trend)
Status: STABLE (<5% rel. variance) | MODERATE (5-15%) | NOISY (>15%)
```

---

## Helpful Error Messages

When commands fail, Runwise provides guidance on what to do.

### No W&B Runs Found (with local logs available)

```bash
runwise list
```

**Output when no wandb/ directory but logs/ exists:**
```
No W&B runs found in wandb/ directory.

Found local JSONL logs instead. Use 'runwise local' commands:
  runwise local                    # List 2 available logs
  runwise local metrics_20251214_115218.jsonl --keys
  runwise local metrics_20251214_115218.jsonl --history -k <metrics>
  runwise local metrics_20251214_115218.jsonl --stats -k <metrics>
```

### No Data Sources Found

```bash
runwise history -k loss
```

**Output when no wandb/ or logs/ exist:**
```
No W&B runs found in wandb/ directory.

Options:
  1. Ensure you're in a directory with wandb/ folder
  2. For local JSONL logs: runwise local <file>
  3. For W&B cloud: runwise api -p <project> (requires: pip install wandb)
```

### Run Not Found

```bash
runwise run xyz999
```

**Output:**
```
Run 'xyz999' not found.

Available W&B runs:
  abc123
  def456
  ghi789
```

### History Data Missing (Killed/Crashed Run)

```bash
runwise history abc123 -k loss
```

**Output when wandb-history.jsonl is missing:**
```
No history data found for run abc123

Missing files:
  - wandb-history.jsonl (not found)
  - output.log (not found)

This commonly happens when:
  1. Run was killed before wandb.finish() was called
  2. Run crashed before history was written
  3. W&B was in offline mode and wasn't synced

To fix for future runs:
  - Use context manager: with wandb.init() as run: ...
  - Or call wandb.finish() explicitly before exit
  - For killed runs: wandb sync <run_dir>

Alternatives:
  runwise stats abc123      # Uses wandb-summary.json (final values only)
  runwise run abc123        # Full run summary
```
